# 理解分布式计算

[https://www.bilibili.com/video/BV11A411L7CK?p=22](https://www.bilibili.com/video/BV11A411L7CK?p=22)

[https://www.bilibili.com/video/BV11A411L7CK?p=23](https://www.bilibili.com/video/BV11A411L7CK?p=23)

[https://www.bilibili.com/video/BV11A411L7CK?p=24](https://www.bilibili.com/video/BV11A411L7CK?p=24)

[https://www.bilibili.com/video/BV11A411L7CK?p=25](https://www.bilibili.com/video/BV11A411L7CK?p=25)

---------------------------------------------------------

定义一个 Task 类，包含了数据和计算逻辑 （Task类就可以理解成一个数据处理模型RDD）

```scala
package com.atguigu.bigdata.spark.core.test

class Task extends Serializable {
    val datas = List(1,2,3,4)
    val logic : (Int)=>Int = _ * 2
}

```

因为要执行分布式计算，任务要发送到多个 executor 上执行，

所以此时，计算逻辑是相同的，但是发送给多个 executor 的数据是不同的。

所以，使用 SubTask 类封装计算逻辑和发送给不同 executor 的数据。 （SubTask类就是一个计算任务，包含了前面定义的数据处理模型Task）

同时，暴露一个 compute 方法，供 executor 使用真正执行计算。

```scala
package com.atguigu.bigdata.spark.core.test

class SubTask extends Serializable {
    var datas : List[Int] = _
    var logic : (Int)=>Int = _

    // 计算
    def compute() = {
        datas.map(logic)
    }
}
```

定义一个 driver, 用来给 executor 发送计算任务。

```
         subtask(data\logic\method)
	    ------------------------------>   executor1

driver
[task]       
	     subtask(data\logic\method)
	    ------------------------------>   executor2


------------------------------------
对比 SPARK RDD


         task(data\logic\method)
	    ------------------------------>  executor1

driver
[rdd]       
	     task(data\logic\method)
	    ------------------------------>   executor2

注意: rdd不保存数据，数据是一直往下流转的
```


```scala
package com.atguigu.bigdata.spark.core.test

import java.io.{ObjectOutputStream, OutputStream}
import java.net.Socket

object Driver {

    def main(args: Array[String]): Unit = {
        // 连接服务器
        val client1 = new Socket("localhost", 9999)
        val client2 = new Socket("localhost", 8888)

        val task = new Task()

        val out1: OutputStream = client1.getOutputStream
        val objOut1 = new ObjectOutputStream(out1)

        val subTask1 = new SubTask()
        subTask1.logic = task.logic
        subTask1.datas = task.datas.take(2)  // 这里发不同的数据

        objOut1.writeObject(subTask1)
        objOut1.flush()
        objOut1.close()
        client1.close()
        // -------------------------------------

        val out2: OutputStream = client2.getOutputStream
        val objOut2 = new ObjectOutputStream(out2)

        val subTask2 = new SubTask()
        subTask2.logic = task.logic
        subTask2.datas = task.datas.takeRight(2)  // 这里发不同的数据
        objOut2.writeObject(subTask2)
        objOut2.flush()
        objOut2.close()
        client2.close()

        println("客户端数据发送完毕")
    }
}

```

定义两个 executor 接收、执行任务

```scala
package com.atguigu.bigdata.spark.core.test

import java.io.{InputStream, ObjectInputStream}
import java.net.{ServerSocket, Socket}

object Executor {

    def main(args: Array[String]): Unit = {

        // 启动服务器，接收数据
        val server = new ServerSocket(9999)
        println("服务器启动，等待接收数据")

        // 等待客户端的连接
        val client: Socket = server.accept()
        val in: InputStream = client.getInputStream
        val objIn = new ObjectInputStream(in)

        // 此时，这里接收到的 task 包含了数据、计算逻辑和暴露的compute方法，即 SubTask 类的所有属性和方法
        val task: SubTask = objIn.readObject().asInstanceOf[SubTask]

        // 执行任务
        val ints: List[Int] = task.compute()   
        println("计算节点[9999]计算的结果为：" + ints)
        objIn.close()
        client.close()
        server.close()
    }
}

```

```scala
package com.atguigu.bigdata.spark.core.test

import java.io.{InputStream, ObjectInputStream}
import java.net.{ServerSocket, Socket}

object Executor2 {

    def main(args: Array[String]): Unit = {

        // 启动服务器，接收数据
        val server = new ServerSocket(8888)
        println("服务器启动，等待接收数据")

        // 等待客户端的连接
        val client: Socket = server.accept()
        val in: InputStream = client.getInputStream
        val objIn = new ObjectInputStream(in)
        val task: SubTask = objIn.readObject().asInstanceOf[SubTask]

        // 执行任务
        val ints: List[Int] = task.compute()
        println("计算节点[8888]计算的结果为：" + ints)
        objIn.close()
        client.close()
        server.close()
    }
}

```