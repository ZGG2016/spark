# 理解并行度

[TOC]

### 并行和并发

并行: 使用多个处理器，或具有多核的单个处理器同时处理多个任务

```
08:00 task1  ---> cpu core1

08:00 task2  ---> cpu core2

08:00 task3  ---> cpu core3
```

并发: 使用一个单核处理器“同时处理”多个任务，但实际上是抢占使用处理器，看起来像是同时处理。

```
08:00 task1  ---> cpu core1  

08:02 task2  ---> cpu core1

08:03 task3  ---> cpu core1
```

### executor core

一个 executor 就是运行在 worker 节点的一个 JVM 进程，它运行 tasks，保存中间数据。

它有三个配置参数:

- nums-executors  executor的数量
- nums-memory	  每个executor的内存大小
- nums-cores	  每个executor的虚拟CPU core

所以，对于一个 executor,

如果给 `nums-cores` 参数分配了三个虚拟核，但实际机器只有一个核，

那么在 executor 内部，这三个虚拟核抢占使用这一个真实核，那么此时就是并发任务，

但如果实际机器也有三个核，一个虚拟核使用一个真实核，那么此时就是并行任务。

### spark中的并行度和分区的区别与联系

给每个 executor 分配一个核:

对一个 RDD 设置三个分区，由于一个分区由一个 task 处理，那么就有三个 task 处理它。

如果存在三个 executor, 那么这三个 task 分别发给这三个 executor 执行, 此时并行度就是3，等同于分区数  （并行执行）

如果仅存在一个 executor, 那么三个 task 抢占使用这个 executor, 此时并行度就是1，不等同于分区数（并发执行）

所以，如果资源充足 `executor core数=task数` 并行度就等于分区数，如果 `executor core数<task数` 就是并发执行。

（结合上面一节理解，这里是任务发送给executor，而上面是executor的事情）

结合下图帮助理解：

![理解并行度](./image/理解并行度.png)

### spark并行度的设置

You can pass the level of parallelism as a second argument (see the spark.PairRDDFunctions documentation), or set the config property spark.default.parallelism to change the default. 

In general, we recommend 2-3 tasks per CPU core in your cluster.  【主要考虑这些任务执行速度不同】


假设我们给当前 spark job 设置总 core 数为 100, 那么依据 1 core 1 task, 当前 spark 集群中最多并行运行 100 task 任务, 那么通过设置并行度参数为 100, 使得我们结果 RDD 的分区数为 100, 一个分区 1task 1core, 完美!

但是实际生产中会有这样的情况, 100 个 task 中有些 task 的处理速度快, 有些处理慢, 假设有 20 个 task 很快就处理完毕了, 此时就会出现我们集群中有 20 个 core 处理闲置状态, 不符合 spark 官网所说的最大化压榨集群能力。

而如果我们设置上述参数值为 199, 此时的现象: 虽然集群能并行处理 199 个 task, 奈何总 core 只有 100, 所以会出现有 99 个 task 处于等待处理的情况. 处理较快的那 20task 闲置下来的 20 个 core 就可以接着运行 99 个中的 20 个 task, 这样就最大化 spark 集群的计算能力。

-------------------------------

参考：

[https://liuxiaocong.blog.csdn.net/article/details/123243056](https://liuxiaocong.blog.csdn.net/article/details/123243056)

[https://www.baifachuan.com/posts/37ccc5d1.html](https://www.baifachuan.com/posts/37ccc5d1.html)
