
spark 组件间通信通过 RpcEnv 通信环境

RpcEnv.scala

```scala
/**
 * A RpcEnv implementation must have a [[RpcEnvFactory]] implementation with an empty constructor
 * so that it can be created via Reflection.
 */
private[spark] object RpcEnv {
    //...

  def create(
      name: String,
      bindAddress: String,
      advertiseAddress: String,
      port: Int,
      conf: SparkConf,
      securityManager: SecurityManager,
      numUsableCores: Int,
      clientMode: Boolean): RpcEnv = {
    val config = RpcEnvConfig(conf, name, bindAddress, advertiseAddress, port, securityManager,
      numUsableCores, clientMode)
    // 通过工厂创建 NettyRpcEnv 
    new NettyRpcEnvFactory().create(config)
  }
}
```

所以，spark 内部使用 Netty 作为通信框架，一种 AIO(异步非阻塞IO)

Linux 对 AIO 支持不够好，采用 Epoll 方式模仿 AIO 操作，而 Windows 支持 AIO。

NettyRpcEnv.scala

```scala
private[rpc] class NettyRpcEnvFactory extends RpcEnvFactory with Logging {
  
  def create(config: RpcEnvConfig): RpcEnv = {
    val sparkConf = config.conf
    // Use JavaSerializerInstance in multiple threads is safe. However, if we plan to support
    // KryoSerializer in future, we have to use ThreadLocal to store SerializerInstance
    val javaSerializerInstance = {
      new JavaSerializer(sparkConf).newInstance().asInstanceOf[JavaSerializerInstance]
      // new一个NettyRpcEnv对象
      val nettyEnv =
        new NettyRpcEnv(sparkConf, javaSerializerInstance, config.advertiseAddress,
          config.securityManager, config.numUsableCores)
      if (!config.clientMode) {
        val startNettyRpcEnv: Int => (NettyRpcEnv, Int) = { actualPort =>
          nettyEnv.startServer(config.bindAddress, actualPort)
          (nettyEnv, nettyEnv.address.port)
        }
        try {
          Utils.startServiceOnPort(config.port, startNettyRpcEnv, sparkConf, config.name)._1
        } catch {
          case NonFatal(e) =>
            nettyEnv.shutdown()
            throw e
        }
      }
      nettyEnv
    }
  }
}
```



